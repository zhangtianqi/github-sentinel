from abc import ABC, abstractmethod
import openai
from github_sentinel.components.config_loader import config
from datetime import datetime, timedelta, timezone


# --- åŸºç±» (ä¿æŒä¸å˜) ---
class BaseSummarizer(ABC):
    """æ‰€æœ‰æ‘˜è¦å™¨çš„æŠ½è±¡åŸºç±»ã€‚"""

    @abstractmethod
    def summarize(self, repo_url: str, updates: dict) -> str:
        """ä¸ºç»™å®šçš„æ›´æ–°ç”ŸæˆæŠ¥å‘Šã€‚"""
        pass

    def _get_report_header(self, repo_url: str) -> str:
        """åˆ›å»ºä¸€ä¸ªæ ‡å‡†çš„æŠ¥å‘Šå¤´éƒ¨ã€‚"""
        return f"# å®šæœŸæŠ¥å‘Š: {repo_url}\n*ç”± GitHub Sentinel ç”Ÿæˆäº {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M')} UTC*\n\n"


# --- SimpleSummarizer çš„å®Œæ•´å®ç° ---
class SimpleSummarizer(BaseSummarizer):
    """
    ç”Ÿæˆä¸€ä¸ªæ ¼å¼åŒ–çš„ã€æœªç» AI å¤„ç†çš„åŸå§‹æ›´æ–°åˆ—è¡¨ã€‚
    å®ƒå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ˜“äºé˜…è¯»çš„ Markdown æŠ¥å‘Šã€‚
    """

    def _format_updates(self, updates: dict) -> str:
        """å°†åŸå§‹æ›´æ–°æ•°æ®æ ¼å¼åŒ–ä¸ºæ¸…æ™°çš„ Markdown æ–‡æœ¬å—ã€‚"""
        content = []

        # 1. æ–°ç‰ˆæœ¬å‘å¸ƒ (Releases)
        if updates.get('releases'):
            content.append("## ğŸš€ æ–°ç‰ˆæœ¬å‘å¸ƒ")
            for r in updates['releases']:
                content.append(f"- **{r['name']} ({r['tag_name']})** ç”± `{r['author']}` å‘å¸ƒã€‚")
            content.append("")  # æ·»åŠ ç©ºè¡Œä»¥åˆ†éš”

        # 2. æœ€æ–°æäº¤ (Commits)
        if updates.get('commits'):
            content.append("## âš™ï¸ æœ€æ–°æäº¤")
            # é™åˆ¶æœ€å¤šæ˜¾ç¤º15æ¡ï¼Œé˜²æ­¢æŠ¥å‘Šè¿‡é•¿
            for c in updates['commits'][:15]:
                content.append(f"- `{c['sha'][:7]}`: {c['message']} (ä½œè€…: `{c['author']}`)")
            if len(updates['commits']) > 15:
                content.append("- ... ä»¥åŠæ›´å¤šæäº¤ã€‚")
            content.append("")

        # 3. æ‹‰å–è¯·æ±‚ (Pull Requests)
        if updates.get('pull_requests'):
            content.append("## ğŸ“¥ æ‹‰å–è¯·æ±‚ (Pull Requests) åŠ¨æ€")
            for pr in updates['pull_requests']:
                status = "âœ… å·²åˆå¹¶/å…³é—­" if pr['state'] != 'open' else "ğŸ“ å¼€å¯ä¸­"
                content.append(f"- `#{pr['number']}` {pr['title']} (ç”± `{pr['user']}`) - **çŠ¶æ€: {status}**")
            content.append("")

        # 4. è®®é¢˜ (Issues)
        if updates.get('issues'):
            content.append("## ğŸ“ è®®é¢˜ (Issues) åŠ¨æ€")
            for issue in updates['issues']:
                status = "âœ… å·²å…³é—­" if issue['state'] != 'open' else "ğŸ“ å¼€å¯ä¸­"
                content.append(f"- `#{issue['number']}` {issue['title']} (ç”± `{issue['user']}`) - **çŠ¶æ€: {status}**")
            content.append("")

        return "\n".join(content)

    def summarize(self, repo_url: str, updates: dict) -> str:
        """
        ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼Œå°†æŠ¥å‘Šå¤´å’Œæ ¼å¼åŒ–åçš„æ›´æ–°å†…å®¹ç»“åˆèµ·æ¥ã€‚
        """
        header = self._get_report_header(repo_url)
        formatted_updates = self._format_updates(updates)

        # å¦‚æœæ ¼å¼åŒ–åçš„æ›´æ–°å†…å®¹ä¸ºç©ºï¼Œåˆ™è¿”å›â€œæ— æ›´æ–°â€æ¶ˆæ¯
        if not formatted_updates.strip():
            return header + "åœ¨è¿‡å»çš„æ—¶é—´æ®µå†…æ²¡æœ‰å‘ç°é‡è¦çš„æ›´æ–°ã€‚"

        return header + formatted_updates


# --- AI æ‘˜è¦å™¨ (ä¿æŒä¸å˜) ---
class AISummarizer(BaseSummarizer):
    # ... (æ­¤å¤„çœç•¥ AISummarizer çš„ä»£ç ï¼Œä¿æŒåŸæ ·å³å¯)
    """Uses an LLM to generate an intelligent summary of updates."""

    def __init__(self):
        llm_config = config.get('llm', {})
        if not llm_config.get('api_key'):
            raise ValueError("LLM configuration ('llm.api_key') is missing in config.yaml for 'ai' summarizer.")
        self.client = openai.OpenAI(api_key=llm_config['api_key'])
        self.model = llm_config.get('model', 'gpt-4o-mini')

    def _format_updates_for_prompt(self, updates: dict) -> str:
        # å¤ç”¨ SimpleSummarizer çš„æ ¼å¼åŒ–æ–¹æ³•æ¥ä¸º AI æä¾›å¹²å‡€çš„è¾“å…¥
        return SimpleSummarizer()._format_updates(updates)

    def summarize(self, repo_url: str, updates: dict) -> str:
        header = self._get_report_header(repo_url)
        update_text = self._format_updates_for_prompt(updates)

        if not update_text.strip():
            return header + "åœ¨è¿‡å»çš„æ—¶é—´æ®µå†…æ²¡æœ‰å‘ç°é‡è¦çš„æ›´æ–°ã€‚"

        system_prompt = (
            "You are GitHub Sentinel, an AI assistant for developer teams. Your task is to analyze a list of recent "
            "GitHub repository activities and provide a high-level summary. The summary should be in Chinese. "
            "Structure the report with clear Markdown headings (e.g., '## å…³é”®æ‘˜è¦', '## éœ€å…³æ³¨çš„æ‹‰å–è¯·æ±‚', '## ä¸»è¦å˜æ›´'). "
            "Focus on what's important for a project manager or team lead to know, avoiding excessive detail. "
            "Start with a brief, high-level 'å…³é”®æ‘˜è¦' section."
        )

        user_prompt = f"è¯·ä¸ºä»¥ä¸‹ä»“åº“æ´»åŠ¨ç”Ÿæˆä¸€ä»½æ‘˜è¦æŠ¥å‘Š:\n\n{update_text}"

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            )
            summary = response.choices[0].message.content
            return header + summary
        except Exception as e:
            print(f"Error calling LLM API: {e}")
            return header + "ç”Ÿæˆ AI æ‘˜è¦æ—¶å‡ºé”™ã€‚\n\n**åŸå§‹æ›´æ–°åˆ—è¡¨:**\n" + update_text


# --- å·¥å‚å‡½æ•° (ä¿æŒä¸å˜) ---
def get_summarizer() -> BaseSummarizer:
    """
    å·¥å‚å‡½æ•°ï¼Œæ ¹æ®é…ç½®è·å–åˆé€‚çš„æ‘˜è¦å™¨ã€‚
    """
    summarizer_type = config.get('summarizer', {}).get('type', 'simple')

    if summarizer_type == 'ai':
        print("Using AI Summarizer.")
        return AISummarizer()
    elif summarizer_type == 'simple':
        print("Using Simple Summarizer.")
        return SimpleSummarizer()
    else:
        print(f"Warning: Unknown summarizer type '{summarizer_type}' in config. Defaulting to 'simple'.")
        return SimpleSummarizer()